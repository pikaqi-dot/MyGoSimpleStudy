//「多核」指的是有效利用 CPU 的多核提高程序执行效率，「并行」和「并发」一字之差，但其实是两个完全不同的概念，「并发」一般是由
//CPU 内核通过时间片或者中断来控制的，遇到 IO 阻塞或者时间片用完时会交出线程的使用权，从而实现在一个内核上处理多个任务，而「并行
//」则是多个处理器或者多核处理器同时执行多个任务，同一时间有多个任务在调度，因此，一个内核是无法实现并行的，因为同一时间只有一个任务在调度：

//多进程、多线程以及协程显然都是属于「并发」范畴的，可以实现程序的并发执行，至于是否支持「并行」，则要看程序运行系统是否是多核，以及编写程
//序的语言是否可以利用 CPU 的多核特性。
//
//下面我们以 goroutine 为例，来演示如何在 Go 语言中通过协程有效利用「多核」实现程序的「并行」执行，具体实现的话就是根据系统 CPU 核心数
//量来分配等值的子协程数，让所有协程分配到每个内核去并行执行。要查看系统核心数，以 MacOS 为例， 可以通过 sysctl hw 命令分别查看物理
//CPU 和逻辑 CPU 核心数
//此外，你也可以在 Go 语言中通过调用 runtime.NumCPU() 方法获取 CPU 核心数。
//
//接下来，我们来模拟一个可以并行的计算任务：启动多个子协程，子协程数量和 CPU 核心数保持一致，以便充分利用多核并行运算，每个子协程计算分
//给它的那部分计算任务，最后将不同子协程的计算结果再做一次累加，这样就可以得到所有数据的计算总和。我们编写对应的示例文件 parallel.go：
package main

import (
	"fmt"
	"runtime"
	"time"
)

func sum(seq int, ch chan int) {
	defer close(ch)
	sum := 0
	for i := 1; i <= 10000000; i++ {
		sum += i
	}
	fmt.Printf("子协程%d运算结果:%d\n", seq, sum)
	ch <- sum
}

func main() {
	// 启动时间
	start := time.Now()
	// 最大 CPU 核心数
	cpus := runtime.NumCPU()
	runtime.GOMAXPROCS(cpus)
	chs := make([]chan int, cpus)
	for i := 0; i < len(chs); i++ {
		chs[i] = make(chan int, 1)
		go sum(i, chs[i])
	}
	sum := 0
	for _, ch := range chs {
		res := <-ch
		sum += res
	}
	// 结束时间
	end := time.Now()
	// 打印耗时
	fmt.Printf("最终运算结果: %d, 执行耗时(s): %f\n", sum, end.Sub(start).Seconds())
}

//这在 CPU 密集型计算中带来的性能提升还是非常显著的，不过对于 IO 密集型计算可能没有这么显著，甚至有可能比单核低，因为 CPU 核心之
//间的切换也是需要时间成本的，所以 IO 密集型计算并不推荐使用这种机制，什么是 IO 密集型计算？比如数据库连接、网络请求等。
//
//另外，需要注意的是，目前 Go 语言默认就是支持多核的，所以如果上述示例代码中没有显式设置 runtime.GOMAXPROCS(cpus) 这行代码，编译
//器也会利用多核 CPU 来执行代码，其结果是运行耗时和设置多核是一样的。
